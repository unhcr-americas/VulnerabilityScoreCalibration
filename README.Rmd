---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# Vulnerability Score Calibration

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![Codecov test coverage](https://codecov.io/gh/unhcr-americas/VulnerabilityScoreCalibration/branch/main/graph/badge.svg)](https://app.codecov.io/gh/unhcr-americas/VulnerabilityScoreCalibration?branch=main)
<!-- badges: end -->

Vulnerability Scores are key tools used to target and prioritize beneficiaries for specific humanitarian Interventions, such as Cash Based Assistance.  

One challenge is to build scoring formulas that allows to reflects __compounded vulnerabilities__, i.e. when different criteria interact with each others. The goal is therefore to prevent __compensability__ (meaning one criteria would be compensated by another one). To do that the geometric aggregations of indicators should be  preferred over arithmetic aggregations (aka multiplying rather than suming). This implies to properly weight each of the criteria used to build the scoring formula. When there's access to a statistically representative dataset of the population such weighting can be performed using a variety of statistical model, but often in humanitarian context such dataset are not available and the weighting is mostly based on expert opinions. 

The goal of {`VulnerabilityScoreCalibration`} is to provide easy access to advanced methods for the calibration of vulnerability scorecard through expert opinions. The goal is to build a process enabling full transparency while building buy-in and consensus among consulted experts.

It combines two approaches based on specific type of surveys that can be used to consults the experts:

 * __Quadratic Voting__: A decision-making and consensus-building method where voting power increases quadratically, allowing individuals to express stronger preferences.
 * __Conjoint Analysis__: A research technique that assesses preferences by presenting individuals with various criteria in combination to determine their relative importance.
 
 Typically, this would be used in the context of a dedicated short workshop where experts will be given to the opportunity to reflect on what vulnerability means within their specific context and understand the requirement on criteria formulation to build effective scoring formula. Then the two consultations are organised (basically a survey to fill within [kobo](https://kobo.unhcr.org)) and expert can review quickly the results to ensure consensus building within a short time frame.

## Process

To implement the approach, beside the workshop facilitation, key technical tasks needs to be performed. They mostly consist in the customization of standard questionnaire and the generation of the results in a format that can be easily consumed by experts within the workshop. For effective facilitation, those tasks should be performed as quickly as possible.

This approach has now been extensively tested by UNHCR within the Americas Region. The resulting tools have been packaged within 4 functions for easy consumptions:

 1. `create_quadratic_survey` - based on a list of criteria, build the [xlsform file](http://xlsform.org) used in kobotoolbox to consult the experts about the relevance of each criteria.  
 
 2. `review_quadratic_consultation` - based on the form and data collected from the experts, generate a slide deck used to review the results from the consultation.  
 
 3. `create_conjoint_survey` - based on a restricted list of criteria and response options within each criteria, build the [xlsform file](http://xlsform.org) used in kobotoolbox to consult the experts about the importance of each criteria.  
 
 4. `review_conjoint_consultation` - based on the form and data collected from the experts, generate a slide deck used to review the results from the consultation together with a csv file with the weights for the score.  

## Installation

The package is accessible through a shiny app @ http://rstudio.unhcr.org 

You can install the development version of {`VulnerabilityScoreCalibration`} from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("unhcr-americas/VulnerabilityScoreCalibration")
```


