# WARNING - Generated by {fusen} from dev/function_documentation.Rmd: do not edit by hand

#' conjoint_review
#' 
#'  What is Conjoint analysis?
#'  
#'  Conjoint analysis can speed up expert consultations by offering an 
#'  __objective mean to compile expert opinions__.
#'  
#'  * Conjoint analysis originated in mathematical psychology by psychometricians.
#'  
#'  * often used to evaluate how people make decisions between a set of 
#'  different options when considering a number of criteria at the same time 
#'  (conjoint features; “trade-offs”). 
#'  
#'  1. Measurement framework
#'  
#'  The Joint Intersectoral Analysis Framework (JIAF) is a theoretical generic 
#'  measurement framework to be used for Humanitarian 
#'  needs assessment. It specifies three distinct and complementary components
#'   of humanitarian severity and vulnerability indexes:
#'    
#'  * Basic Needs & Living standards  
#'  
#'  * Coping Capacity
#'  
#'  * Well Being & Community integration
#'  
#'  This generic model can be contextualized: different sub-indicators might be 
#'  used for each of the 3 components depending on cultural and political situations. 
#'  
#'  2. Define the combined alternatives to be compared 
#'  
#'  * participants rate their preferences for profiles with different combinations
#'   of the attributes or criteria. 
#'  
#'  * CA then allows to “decompose” or reverse-engineer these ratings into
#'   estimates of how important each criteria or attribute is to a participant’s ranking decisions
#'  
#'  3. Utility scales & Agreement levels
#'  
#'  Estimating the contribution of each potential answers
#'  
#'  * Utility values indicate the overall contribution of each attribute to how 
#'  the profiles were rated (e.g. whether number of meals is more important in 
#'  vulnerability scoring than access to safe water). 
#'  
#'  * A higher _"utility"_ estimate indicates that this level contributes to a
#'   higher vulnerability than the level with the lower utility estimate 
#'   (it does not give an absolute value for the utility of an option, but rather
#'    assumes a reference alternative). 
#'  
#'  * Standard deviation for each level within model allows to better understand 
#'  how homogeneous the group of experts is with respect to one level.  
#'  
#'  4. Importance of each criteria 
#'  
#'   * Importance of each criteria represent the average importance as estimated from all experts.
#'  
#'   * Importance values will then be used as the weights for each attribute inside each of our three dimensions. 
#'  
#'   * Importance values sum to 100%. 
#'   
#' @param kobodata path to data collected through kobotoolbox
#' @param koboform form used to collected through kobotoolbox quadratic survey
#' @param  duration_min used to filter down expert contribution that would have 
#'                       taken less than a certain number of minutes (default is 10)  
#' @param  duration_max used to filter down expert contribution that would have 
#'                       taken more than a certain number of minutes (default is 40)   
#'   
#' @import ggplot2
#' @import patchwork
#' @importFrom unhcrthemes theme_unhcr
#' @import survival
#' @import sandwich
#' @import conjoint
#' 
#' @importFrom readxl read_excel
#' @importFrom stringr str_c str_replace str_match
#' @importFrom purrr compose
#' @importFrom tidyr separate_rows nest pivot_longer  pivot_wider
#' @importFrom cregg cj mm
#' @importFrom stats mahalanobis cov as.formula pchisq
#' @importFrom forcats as_factor
#' @importFrom lubridate as.duration
#' @importFrom tidyselect starts_with
#' @importFrom  dplyr select mutate distinct transmute
#'                    with_groups  as_tibble rowwise
#'                   arrange row_number anti_join first
#'                   across everything where summarize
#' 
#' @return a series of plot
#' 
#' @export
#' @examples
#'
#' kobodata <-  system.file("data-demo/conjoint_data.xlsx", package = "VulnerabilityScoreCalibration")
#' koboform <-  system.file("data-demo/conjoint_form.xlsx", package = "VulnerabilityScoreCalibration") 
#'
#' cj <- conjoint_review(kobodata, koboform)
#'
#' cj[["data_quality"]]
conjoint_review <- function(kobodata, 
                            koboform,
                            duration_min = 10, 
                            duration_max = 40){

  
  ## load info from the form
  form <- readxl::read_excel(koboform,
                       sheet = "survey") |>
        ## Rename and use what ever label set is coming first 
        dplyr::rename(label = dplyr::first(tidyselect::starts_with("label")),
                        hint = dplyr::first(tidyselect::starts_with("hint")))
  
  ## Get the levels for all indicators
  opts <- readxl::read_excel(koboform,
                       sheet = "opts") |> 
          dplyr::mutate( dplyr::across(
            .cols = dplyr::everything(),
            ~ stringr::str_replace( ., "\r", "" )   ) )
     
  ## Get the list of indicators
  dict <- opts |>
    dplyr::distinct(dim, measure) |>
    dplyr::arrange(dim, measure) |>
    dplyr::with_groups(dim, 
                       mutate, 
                       feature = stringr::str_c("v", 
                                                dplyr::row_number()))
  

  ## load data
  data <- readxl::read_excel(kobodata,
                         sheet = 1)
  
  ## extracting the scores
  scores <- data |>
    dplyr::select(email, dplyr::starts_with("p.")) |>
    tidyr::pivot_longer(-email, names_to = "var")
  
  ## Recombine per dimension.. 
  dims <- data |>
    dplyr::select(starts_with("p.")) |>
    names() |>
    stringr::str_match("p\\.(.+)\\.(.+)") |>
    dplyr::as_tibble(.name_repair = "universal") |>
    dplyr::rename(var = ...1, dim = ...2, lvl = ...3) |>
    dplyr::left_join(form |> 
                       dplyr::select(lvl = name, label = `label`), 
                     by = "lvl") |>
    tidyr::separate_rows(label, sep = "\\n") |>
    dplyr::with_groups(lvl, mutate, 
                       feature = stringr::str_c("v", 
                                                dplyr::row_number())) |>
    dplyr::left_join(dict, by = dplyr::join_by(dim, feature)) |> 
    dplyr::select(-feature) |>
    tidyr::pivot_wider(names_from = measure, values_from = label) |>
    dplyr::mutate(dplyr:::across(-c(var:lvl), forcats::as_factor)) 

    #uncommented as_factor
    #   ~factor(., levels = opts |> filter(measure == cur_column()) |> pull(level)))) 
    
    
    ## Data Quality Review
  plot1 <- data |>
    ggplot(aes(as.numeric(survey_mins))) +
    geom_histogram(color = "white", 
                   fill = "#0072BC",
                   bins = 10) +
    scale_y_continuous(expand = expansion(0, 0)) +
    labs(subtitle = "Times to complete the consultation",
         x = "(minutes)", y = "# of participants") +
    unhcrthemes::theme_unhcr(font_size = 14, grid = "y")
  
  plot2 <- data |>
    dplyr::reframe(mean = rowMeans(data |> 
                                       dplyr::select(starts_with("p.")))) |>
    ggplot(aes(mean)) +
    geom_histogram(colour = "white",
                   fill = "#0072BC",
                   binwidth = 1) +
    scale_y_continuous(expand = expansion(0, 0)) +
    labs(subtitle = "Average score",
         x = "# de participantes", y = "") +
    unhcrthemes::theme_unhcr(font_size = 14, grid = "y")
  
    #require(patchwork)
    p <- plot1 + plot2 + plot_annotation(title = "Before cleaning", caption = glue::glue("Based on {nrow(data)} consultations"))
  
  ## Data Cleaning 
  # Assessment that were completed too fast or too slow are suspect
  # and should be considered for deletion. 
   data_clean <-  data |>
    dplyr::mutate(
      dur = lubridate::as.duration(end - start) |> 
        as.numeric("minutes"),
      too_short = dur < duration_min,
      too_long = dur > duration_max,
      suspect = too_short | too_long,
      too_short2 = survey_mins < duration_min,
      too_long2 = survey_mins > duration_max,
      suspect_duration = too_short2 | too_long2   ) #|>
     #dplyr::filter(! suspect2)
   
  # Cleaning for duplicates based on name of expert.
  # if Duplicate Kept shortest time.
  # expert_duplication <-   data |>
  #                 dplyr::semi_join(count(., email) |>
  #                      dplyr::filter(n > 1))
    
   # data_id_duplication <-  data_clean |>
   #  # dplyr::select(email, survey_mins ) |>
   #    dplyr::group_by(email) |>
   #    #dplyr::summarize(across(everything(), min)) 
   #    dplyr::summarize(across(all_of(survey_mins) , min)) 
   # 
   #  data_clean <- data_clean |> 
   #    dplyr::anti_join(data_id_duplication , 
   #                     by = "email")
  
  #FOR TIME: It is recommended that experts complete the survey during the live exercise. 

  #This code generated the table of flagged entries. click on 'expert_validation'
  #on the Environment to see the table. If you identify any entry flagged as suspect,
  #but that you still want to keep, change the reference values 10 or 90. 
  # data.dur <-  data |>
  #   dplyr::transmute(
  #     dur = lubridate::as.duration(end - start) |> 
  #       as.numeric("minutes"),
  #     too_short = dur < duration_min,
  #     too_long = dur > duration_max,
  #     suspect = too_short | too_long,
  #     too_short2 = survey_mins < duration_min,
  #     too_long2 = survey_mins > duration_max,
  #     suspect2 = too_short2 | too_long2
  #   )
  # data_clean <- data |> 
  #     dplyr::anti_join(time_validation |> 
  #                        dplyr::filter(suspect2), 
  #                      by = "email")


   
  # Spotting outliers using Mahalanobis distanceto detect repetitive responses 
  # (example: answered all options with '3'), responses 
  # with little variance (all answers between 6-7, standard deviation less than 2). 
  # Also looks for averages that are very different from the rest of the responses.
  # For example, someone's average score is 2 when the rest of the scores are 
  # between 6-7. Analysis can be repeated with and without this case to test and 
  # compare how it influences the results. 
    
    ## EXTRACT SCORE ONLY
    data.score <-   data_clean |> 
      dplyr::select(starts_with("p.")) |> 
      dplyr::select(where(is.numeric)) 
   
    #average mahalanobis distances of each row from the whole data set.
    mahalnobisval <- stats::mahalanobis(data.score,
                                    colMeans(data.score),
                                    stats::cov(data.score),
                                 tol = 1e-21)
    #just added this ", tol=1e-21" right after cov(.). After error message:
    #"system is computationally singular: reciprocal condition number = 4.08252e-20 
   
    pvalue <- stats::pchisq(mahalnobisval, 
                                df=3,
                                lower.tail=FALSE)
    pchi <- stats::pchisq(.99,  df = 3 )
    
    ## Bind outlier check!
    data_clean <- cbind(data_clean, mahalnobisval, pvalue, pchi)  |>
      dplyr::mutate(outlier_mahalnobis = dplyr::if_else(pvalue < 0.001, TRUE, FALSE),
                    outlier_mahalnobis2 = dplyr::if_else(mahalnobisval > pchi, TRUE, FALSE))  
    
# 
#   data_clean |>
#     dplyr::select(email,survey_mins,  suspect, suspect_duration, mahalnobisval,outlier_mahalnobis, outlier_mahalnobis2 )


  
    
    
  
    ## Compile results!!
    cjdata <-  dplyr::left_join(dims, scores, by = "var") |>
          tidyr::nest(data = -dim) |>
          dplyr::rowwise() |>
          ## Compile all the calculations!!
          dplyr::mutate(
            data = data |> 
              select(- purrr::compose( purrr::compose(all, is.na))) |> 
              list(),
            formula =
              data |>
              dplyr::select(where(is.factor)) |>
              names() |>
              stringr::str_c(collapse = "+") |>
              stringr::str_c("value", 
                             vars = _, 
                             sep = "~"),
              margins = cregg::mm(data, stats::as.formula(formula), id = ~ email) |> 
              list(),
            amces =
              cregg::cj(data, 
                        stats::as.formula(formula),
                        id = ~ email) |>
              dplyr::group_by(feature) |>
              dplyr::mutate(
                normalized = (estimate - min(estimate)) / 
                                (max(estimate) - min(estimate)),
                horizontal = (estimate - min(estimate)),
                normalized1p = normalized + 1,
                horizontal1p = horizontal + 1 ) |> 
              dplyr::ungroup() |> 
              list(),
            importance =
              dplyr::as_tibble(amces) |>
              dplyr::mutate(
                estimate = abs(estimate) / sum(abs(estimate)),
                lower = abs(lower) / sum(abs(lower), na.rm = TRUE),
                upper = abs(upper) / sum(abs(upper), na.rm = TRUE)  ) |> 
              list()
          )


 

  results <- list(
    cjdata = cjdata,
    weights = df <- plyr::ldply(cjdata$amces, data.frame) |>
                dplyr::select(feature, level, normalized1p),
    data_quality = p
  )
   return(results)
}
